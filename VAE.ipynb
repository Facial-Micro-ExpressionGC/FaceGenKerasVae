{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model, Model, Input\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from statsmodels.robust import mad\n",
    "import random\n",
    "import cv2\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = (192, 192, 3) # Image dimensions\n",
    "numdim = 30 # Number of latent dimensions\n",
    "\n",
    "def sample(args):\n",
    "    z_mu, z_log_sigma = args\n",
    "    epsilon = K.random_normal((K.shape(z_mu)[0], numdim),)\n",
    "    return z_mu + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "class CustomLossLayer(keras.layers.Layer):\n",
    "    def vae_loss(self, x, z_decoded):\n",
    "        x = K.flatten(x)\n",
    "        z_decoded = K.flatten(z_decoded)\n",
    "        \n",
    "        # Reconstruction loss\n",
    "        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
    "        \n",
    "        # KL divergence\n",
    "        kl_loss = -5e-4 * K.mean(1 + z_log_sigma - K.square(z_mu) - K.exp(z_log_sigma), axis=-1)\n",
    "        \n",
    "        return K.mean(xent_loss + kl_loss)        \n",
    "\n",
    "    # Adds the custom loss\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        z_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, z_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        return z_decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_img = Input(imsize)\n",
    "\n",
    "x = Conv2D(32, 4,\n",
    "          activation = 'relu',\n",
    "          strides = 2,\n",
    "          padding = 'same')(input_img)\n",
    "\n",
    "x = Conv2D(64, 4,\n",
    "          activation = 'relu',\n",
    "          strides = 2,\n",
    "          padding = 'same')(x)\n",
    "\n",
    "x = Conv2D(128, 4,\n",
    "          activation = 'relu',\n",
    "          strides = 2,\n",
    "          padding = 'same')(x)\n",
    "\n",
    "x = Conv2D(128, 4,\n",
    "          activation='relu',\n",
    "          padding = 'same')(x)\n",
    "\n",
    "x = Conv2D(128, 4,\n",
    "          activation = 'relu',\n",
    "          padding = 'same')(x)\n",
    "\n",
    "x = Conv2D(256, 4,\n",
    "          activation = 'relu',\n",
    "          padding='same')(x)\n",
    "\n",
    "x = Conv2D(256, 4,\n",
    "          activation = 'relu',\n",
    "          padding = 'same')(x)\n",
    "\n",
    "x = Conv2D(256, (1,4),\n",
    "          activation = 'relu',\n",
    "          padding = 'same')(x)\n",
    "\n",
    "b4shape = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "z_mu = Dense(numdim)(x)\n",
    "z_log_sigma = Dense(numdim)(x)\n",
    "z = Lambda(sample)([z_mu, z_log_sigma]) # Combining z_mu and z_log_sigma\n",
    "z = BatchNormalization()(z)\n",
    "\n",
    "encoder = Model(input_img, z) # Assigns half the VAE\n",
    "\n",
    "decoder_input = Input(K.int_shape(z)[1:])\n",
    "\n",
    "x = Dense(np.prod(b4shape[1:]),\n",
    "          activation = 'relu')(decoder_input)\n",
    "\n",
    "x = Reshape(b4shape[1:])(x)\n",
    "\n",
    "x = Conv2DTranspose(256, (4,1), \n",
    "                  activation = 'relu',\n",
    "                  padding='same')(x)\n",
    "\n",
    "x = Conv2DTranspose(256, 4, \n",
    "                  activation = 'relu',\n",
    "                  padding='same')(x)\n",
    "\n",
    "x = Conv2DTranspose(256, 4, \n",
    "                  activation = 'relu',\n",
    "                  padding='same')(x)\n",
    "\n",
    "x = Conv2DTranspose(256, 4, \n",
    "                  activation = 'relu',\n",
    "                  padding = 'same')(x)\n",
    "\n",
    "x = Conv2DTranspose(128, 4, \n",
    "                  activation = 'relu',\n",
    "                  padding = 'same',)(x)\n",
    "\n",
    "x = Conv2DTranspose(128, 4,  \n",
    "                  activation = 'relu',\n",
    "                  padding = 'same')(x)\n",
    "\n",
    "x = Conv2DTranspose(64, 4,  \n",
    "                  activation = 'relu',\n",
    "                  padding = 'same')(x)\n",
    "\n",
    "x = Conv2DTranspose(32, 4,  \n",
    "                 activation = 'relu',\n",
    "                 padding = 'same')(x)\n",
    "\n",
    "x = Conv2DTranspose(24, 4,  \n",
    "                  activation = 'relu',\n",
    "                  padding = 'same',\n",
    "                   strides = 2)(x)\n",
    "\n",
    "x = Conv2DTranspose(9, 4,  \n",
    "                  activation = 'relu',\n",
    "                  padding = 'same',\n",
    "                  strides = 2)(x)\n",
    "\n",
    "x = Conv2DTranspose(3, 6, \n",
    "          padding = 'same', \n",
    "          activation = 'sigmoid',\n",
    "          strides = 2)(x)\n",
    "\n",
    "decoder = Model(decoder_input, x) # Assigns half the VAE\n",
    "\n",
    "z_decoded = decoder(z)\n",
    "\n",
    "y = CustomLossLayer()([input_img, z_decoded]) # Adds loss\n",
    "\n",
    "def no_loss(y_true, y_pred): # Because loss is given in the custom layer\n",
    "    return y_pred-y_pred\n",
    "\n",
    "vae = Model(input_img, y) # Assigns the combined encoder-decoder model\n",
    "vae.compile(optimizer=Adam(lr=0.00146), loss=no_loss) \n",
    "\n",
    "plot_model(vae, 'vae_architecture.png', show_shapes = True) # Plots model architecture to a file\n",
    "plot_model(decoder, 'decoder_architecture.png', show_shapes = True)\n",
    "\n",
    "print('AUTOENCODER ARCHITECTURE (\"model\" is the decoder)')\n",
    "vae.summary()\n",
    "print('DECODER ARCHITECTURE')\n",
    "decoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_weights('vae_192_30.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae.save('vae_192_30.h5py')\n",
    "# vae.save_weights('vae_w_192_30.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# image feeder for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'manyfaces', # Folder name with all the images. Inside the folder should be ANOTHER folder with images\n",
    "        target_size=imsize[:-1],\n",
    "        batch_size=16,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training\n",
    "epochs = 0\n",
    "while True:\n",
    "    vae.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=16054//16,\n",
    "            epochs=1,)\n",
    "    epochs +=1\n",
    "    print(epochs)\n",
    "    vae.save('vae_192_30.h5py')\n",
    "    vae.save_weights('vae_w_192_30.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube channel Code Parade explains this in his video on generating faces.\n",
    "def save_PCA_stuff(rand_vecs, iters):\n",
    "    x_enc = encoder.predict_generator(\n",
    "            train_generator,\n",
    "            steps=13233//16,)\n",
    "\n",
    "    x_mean = np.mean(x_enc, axis=0)\n",
    "    x_stds = np.std(x_enc, axis=0)\n",
    "    x_cov = np.cov((x_enc - x_mean).T)\n",
    "    e, v = np.linalg.eig(x_cov)\n",
    "\n",
    "    np.save('means.npy', x_mean)\n",
    "    np.save('stds.npy', x_stds)\n",
    "    np.save('evals.npy', e)\n",
    "    np.save('evecs.npy', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_PCA_stuff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell creates a 16x9 grid of nearly 300 faces and saves it to a PNG file while also showing it\n",
    "'''\n",
    "\n",
    "# Loading PCA stuff\n",
    "x_mean = np.load('means.npy',)\n",
    "x_stds = np.load('stds.npy', )\n",
    "e = np.load('evals.npy', )\n",
    "v = np.load('evecs.npy', )\n",
    "\n",
    "fig = plt.figure(figsize=(16,9), dpi = 194)\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "for i in range(1,16*9+1):\n",
    "        ax = plt.subplot(9, 16, i)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        vector = np.array([np.random.uniform(-2, 2) for i in range(30)])\n",
    "        vector = x_mean + np.dot(v, (vector * e).T).T\n",
    "        vector*=6.1\n",
    "        np.clip(vector, -0.45, 0.45, vector)\n",
    "        plt.imshow(decoder.predict(vector.reshape(1,30)).reshape(192,192,3))\n",
    "plt.savefig('ManyFaces1.PNG', bbox_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This cell generates a random face. Press any keyboard button to make a new face. Quickly press one button and then press Q to exit\n",
    "'''\n",
    "# Loading PCA stuff\n",
    "x_mean = np.load('means.npy',)\n",
    "x_stds = np.load('stds.npy', )\n",
    "e = np.load('evals.npy', )\n",
    "v = np.load('evecs.npy', )\n",
    "while True:\n",
    "    vector = np.array([np.random.uniform(-2, 2) for i in range(30)])\n",
    "    vector = x_mean + np.dot(v, (vector * e).T).T\n",
    "    vector*=6.1\n",
    "    np.clip(vector, -0.5, 0.5, out=vector)\n",
    "    \n",
    "    print(vector.max(), vector.min(),  vector.mean(), mad(vector, axis=0))\n",
    "    clear_output(True)\n",
    "    \n",
    "    image = (decoder.predict(vector.reshape(1,numdim)).reshape(*imsize)*255).astype('uint8')\n",
    "    \n",
    "    cv2.imshow('image', cv2.cvtColor(cv2.resize(image, (600,600)), cv2.COLOR_RGB2BGR))\n",
    "    plt.show()\n",
    "    if cv2.waitKey(100)&0xFF == ord('q'):\n",
    "        break\n",
    "    if cv2.waitKey(0):\n",
    "        continue\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell is for a face editor with sliders and stuff so you can make custom faces. I recommend downloading a program that keeps the face window on top so u can see the changes taking place. Press Q to exit\n",
    "'''\n",
    "\n",
    "# Loading PCA stuff\n",
    "x_mean = np.load('means.npy', )\n",
    "x_stds = np.load('stds.npy', )\n",
    "e = np.load('evals.npy', )\n",
    "v = np.load('evecs.npy', )\n",
    "\n",
    "# The next few lines make trackbars in descending order of effect on the image\n",
    "enumer = list(enumerate(e.tolist()))\n",
    "enumer = pd.DataFrame(enumer)\n",
    "effect_indexes = np.array(enumer.sort_values(1, ascending=False))[:,0].astype('int').tolist()\n",
    "nums = [str(i) for i in range(numdim)]\n",
    "\n",
    "def no(x): # Uselsess function needed for cv2.createTaskbar\n",
    "    pass\n",
    "cv2.namedWindow('sliders')\n",
    "\n",
    "for i in effect_indexes:\n",
    "    cv2.createTrackbar(str(i),'sliders', random.randint(350, 650), 1000, no)\n",
    "\n",
    "while True:\n",
    "    feedin = []\n",
    "    for i in nums:\n",
    "        feedin.append(norm.ppf((cv2.getTrackbarPos(i,'sliders')+1)/1002))\n",
    "    feedin = np.array(feedin)\n",
    "    feedin *= 15\n",
    "    feedin = x_mean + np.dot(v, (feedin * e).T).T\n",
    "    \n",
    "    #np.clip(feedin, -0.5, 0.5, feedin)\n",
    "    feedin = feedin.reshape(1,numdim)\n",
    "    image = decoder.predict(feedin)\n",
    "    image = (image.reshape(*imsize)*255).astype('uint8')\n",
    "    \n",
    "    print(feedin.max(), feedin.min(), feedin.mean(), *mad(feedin, axis=1), sep='\\n')\n",
    "    print(feedin.round(1))\n",
    "    clear_output(True)\n",
    "    \n",
    "    cv2.imshow('image', cv2.cvtColor(cv2.resize(image, (500,500)), cv2.COLOR_RGB2BGR))\n",
    "    if cv2.waitKey(1)&0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This cell creates video of a smoothly changing random face. press Q to exit\n",
    "'''\n",
    "\n",
    "\n",
    "x_mean = np.load('means.npy',)\n",
    "x_stds = np.load('stds.npy', )\n",
    "e = np.load('evals.npy', )\n",
    "v = np.load('evecs.npy', )\n",
    "\n",
    "\n",
    "# Initializes a random vector\n",
    "feedin = np.zeros((1,numdim))\n",
    "for i in range(numdim):\n",
    "    feedin[:,i] = np.random.uniform(-0.1,0.1)\n",
    "add = np.zeros((1,numdim))\n",
    "for i in range(numdim):\n",
    "    add[:,i]+=np.random.uniform(0.1, -0.1)\n",
    "\n",
    "while True:\n",
    "    # slightly change the vector\n",
    "    for i in range(numdim):\n",
    "        add[:,i]+=np.random.uniform(-0.6*add.max(),-0.6*add.min()) \n",
    "        if np.random.uniform(-0.5, 1)<0: # 33 % chance each value in the vector becomes 5% smaller\n",
    "            add[:, i]*=0.95\n",
    "            \n",
    "    np.clip(add, -0.5, 0.5, add)\n",
    "    for i in range(numdim):\n",
    "        feedin[:, i]+=add[:,i]\n",
    "        if np.random.uniform(-0.5, 1)<0: # 33 % chance each value in the vector becomes 5% smaller\n",
    "            feedin[:, i]*=0.95\n",
    "        if feedin[:, i] in [feedin.max(), feedin.min()]: # decreases the smallest and largest value by 5%\n",
    "            feedin[:, i] *= 0.95 \n",
    "            \n",
    "    # do some fancy PCA stuff on the vector to make faces look better. 'n' stands for 'new'\n",
    "    nfeedin = x_mean + np.dot(v, (feedin * e).T).T\n",
    "    nfeedin*=1\n",
    "    np.clip(nfeedin, -0.2, 0.2, nfeedin)\n",
    "    clear_output(True)\n",
    "    feedin -= feedin.mean()\n",
    "\n",
    "    print(nfeedin.max(), nfeedin.min(), nfeedin.mean(), *mad(nfeedin, axis=1), sep='\\n') #info on whats being fed into the decoder\n",
    "    print(nfeedin.round(2))\n",
    "    \n",
    "    image = decoder.predict(nfeedin)\n",
    "    image = (image.reshape(*imsize)*255).astype('uint8')\n",
    "    image = cv2.cvtColor(cv2.resize(image, (192*2,192*2), interpolation = cv2.INTER_LANCZOS4), cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow('image', image)\n",
    "    if cv2.waitKey(15)&0xFF == ord('q'): # Decrease value to make changing faster\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
